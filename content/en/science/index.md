---
title: "Science"
description: ""
date: 2022-08-01T09:25:27+02:00
lastmod: 2022-08-01T09:25:27+02:00
draft: false
images: []
---

At Possible Worlds, we have developed a unique approach to building AI systems. 

## Current challenges
The current state-of-the-art, as developed by large corporations, involves scaling neural networks and training them over an increasingly larger amount of data. We think this standard methodology has many problems:

* development of AI solutions is restricted to organizations with the enormous financial means it takes to run those algorithms;
* the generation of each new AI model produces unacceptable amounts of CO2, the cost of which is born by the entire planet;
* there is no assurance that intelligence will actually emerge from such systems, as there is no (cognitive) theory supporting the practice of scaling neural systems.


Instead, Possible Worlds is working on solutions based on two recognized fields of science: formal semantics and cognitive neuroscience.

## Formal semantics
Formal semantics is a subfield of theoretical linguistics, which has been in existence for over 50 years. It aims at describing the way that language relates to the world, using the formal tools of mathematics. Up to recently, integration of formal semantics into AI systems was seen as particularly difficult, because the particular logical structures of linguistics were hard to encode into a form that could easily be learned by computers. This is however changing, as new solutions are being proposed by the scientific community. This evolution has the potential to unlock vital aspects of intelligence that current AI systems cannot acquire.

## Cognitive neuroscience
Cognitive neuroscience combines methodologies from the fields of cognitive science, neurobiology and computer science. Recent advances in that area have shown that brain activations, as measured by neuroimaging methods, can be translated into the type of representations learned by AI systems over big data. More fascinatingly, there is evidence that different cognitive functions might be encoded in 'brain spaces' of low dimensionality. In lay terms, this means that different features of our cognition can be encoded in many less neurons than is assumed by the large AI systems that have been making into the news in the last few years. Such insights pave the way for smaller models that anybody can run, even on basic hardware.
